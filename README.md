# Time Series Forecasting (Energy Consumption)

### Introduction 

In this reposity I create an end to end machine learning pipeline that predicts energy consumption, deploy this model using batch processing. In data science energy consumption forecasting can be modelled as a regression problem. There is a lot of economic, social, and environmental value that can come from the ability to accurately predict energy consumption. This project aims to research and understand the fundamentals of clean energy, energy generation, distribution and consumption and how energy consumption forecasting is cruicial in the Energy Sector. 


## Readme Table of Contents 

1. Project Objectives

  1. Domain knowledge and problem statment
     
  2. Technical

2. Flow Diagram
3. Full Machine learning Pipeline
4. Features to add in the future
5. Repreducibility
6. Aknowledgments




### Project Objectives 

#### 1. Domain Knowledge and problem statement Overview

  Research and understand the problem 
  Research and understand potential and applied solutions 
  Use research findings to create featrues to improve models predicitve power 
  
  example weather conditions, public holidays, economic indicators, events like sports tournaments or concerts
  
  
  Energy consumption forecasting advantages include but are not limited to 
  
  * Reducing energy consumption and carbon footprint
  * Improved Grid Effeciency and therefore increase cost savings
  * Inhnaced renewable energy integration
  * Informed decision making and resource allocation
  * Real time demand balancing which helps prevent imbalances and reduce the risk of blackouts
  


#### 2. Technical Overview 

In this project, the goal is to build an end-to-end ML project and implement MLOps process and best practices. The project is structured into six main components:

1. **Dataset**: Acquire and prepare the dataset.
2. **Train a model**: Train a model using the dataset and track the experimentation process.
3. **Create a model training pipeline**: Set up a pipeline for training the model.
4. **Deploy the model**: Deploy the model using batch processing, web services, or streaming.
5. **Monitor the model's performance**: Keep track of the model's performance over time.
6. **Follow best practices**, including:
   - Testing (unit and integration testing).
   - Python linting and formatting.
   - Implementing pre-commit hooks and makefiles.
   - Setting up CI/CD using GitHub Actions.
   - Implementing Infrastructure as Code (Terraform).


#### Technologies 

**Technologies Used:**

- **Cloud**: AWS, GCP, Azure, or others
- **Experiment tracking tools**: MLFlow, Weights & Biases, and more.
- **Workflow orchestration**: Prefect, Airflow, Flyte, Kubeflow, Argo, and more.
- **Monitoring**: Evidently, WhyLabs/whylogs, and more.
- **CI/CD**: GitHub Actions, Gitlab CI/CD, and more.
- **Infrastructure as Code (IaC)**: Terraform, Pulumi, Cloud Formation, and more.



















This project is done after going through the course material from [mlops-zoomcamp](https://github.com/MarwanH7/mlops-zoomcamp)
